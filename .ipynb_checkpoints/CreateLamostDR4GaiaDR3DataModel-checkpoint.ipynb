{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LAMOST data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import DataModel as DM\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import MilkyWaySF\n",
    "import CoordTrans as ct\n",
    "import dill\n",
    "\n",
    "### USER-DEFINED PARAMETERS #########################################################\n",
    "DATAFILE        = \"../data/LMRC-DR4-VF-SNR30-Gaia.csv\"\n",
    "SFFILE          = \"../results/selfunc/selfunc_with_redclumpsel_highres.dill\" # File with red clump selection file\n",
    "NMC             = 10                # Number of Monte Carlo sample for error convolution integral\n",
    "DISCSETUP       = \"DoubleDisc\"      # Configuration of thin disk\n",
    "MODELTYPE       = \"all\"\n",
    "ZMIN            = 0.6               # Minimum z below and above plane\n",
    "ZMAX            = 1.0               # Maximum z above and below plane \n",
    "if (MODELTYPE==\"zsel\"):\n",
    "    MCFILE          = \"../results/fit/\"+DISCSETUP+\"/abovePlane/mcsamp_nmc\"+str(NMC)+\".txt\" # Where to store Monte Carlo samples\n",
    "    DATAMODELFILE   = \"../results/fit/\"+DISCSETUP+\"/abovePlane/datamodel_nmc\"+str(NMC)+\".dill\" # Where to store pickled datamodel isntance\n",
    "else:\n",
    "    MCFILE          = \"../results/fit/\"+DISCSETUP+\"/all/mcsamp_nmc\"+str(NMC)+\".txt\" # Where to store Monte Carlo samples\n",
    "    DATAMODELFILE   = \"../results/fit/\"+DISCSETUP+\"/all/datamodel_nmc\"+str(NMC)+\".dill\" # Where to store pickled datamodel isntance\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read LAMOST DR4 red clump-Gaia DR2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LAMOST DR4 red clump supplemented with Gaia DR2 ...\n",
      "Replaced 16 stars with missing Gaia data with original data...\n",
      "Replaced 446 stars having NaN proper motions with original UCAC5 proper motions...\n",
      "Removing 5211 stars that are likely to be merged stars.\n",
      "Removing a further 16592 stars that belong to the high-alpha disc.\n",
      "Removing a further 85415 stars that are beyond the selection in z.\n",
      "22771\n",
      " \n"
     ]
    }
   ],
   "source": [
    "lamostgaia = pd.read_csv(DATAFILE)\n",
    "\n",
    "# Collect coordinates (ra/rad, dec/rad, s/kpc, vr/kms-1, mura/masyr-1, \n",
    "# mudec/masyr-1, [Fe/H]/dex, [a/Fe]/dex, age/Gyr)\n",
    "Obs = np.column_stack((lamostgaia[\"gaiadr2_ra\"]/180.*np.pi,\n",
    "                       lamostgaia[\"gaiadr2_dec\"]/180.*np.pi,\n",
    "                       lamostgaia[\"s\"],\n",
    "                       lamostgaia[\"vr\"],\n",
    "                       lamostgaia[\"gaiadr2_pmra\"],\n",
    "                       lamostgaia[\"gaiadr2_pmdec\"],\n",
    "                       lamostgaia[\"feh\"],\n",
    "                       lamostgaia[\"afe\"],\n",
    "                       lamostgaia[\"age\"]))\n",
    "feh = np.copy(lamostgaia[\"feh\"])\n",
    "afe = np.copy(lamostgaia[\"afe\"])\n",
    "\n",
    "eObs = np.column_stack((lamostgaia[\"gaiadr2_ra_error\"]/180.*np.pi,\n",
    "                        lamostgaia[\"gaiadr2_dec_error\"]/180.*np.pi,\n",
    "                        lamostgaia[\"es\"],\n",
    "                        lamostgaia[\"evr\"],\n",
    "                        lamostgaia[\"gaiadr2_pmra_error\"],\n",
    "                        lamostgaia[\"gaiadr2_pmdec_error\"],\n",
    "                        lamostgaia[\"efeh\"],\n",
    "                        lamostgaia[\"eafe\"],\n",
    "                        lamostgaia[\"eage\"]))\n",
    "print(\"Read LAMOST DR4 red clump supplemented with Gaia DR2 ...\")\n",
    "                       \n",
    "# Replace stars without Gaia matches with original sky positions and proper motions\n",
    "index = (lamostgaia[\"gaiamatch\"]==False) \n",
    "Obs[index,0]  = lamostgaia[\"ra\"][index]/180.*np.pi\n",
    "Obs[index,1]  = lamostgaia[\"dec\"][index]/180.*np.pi\n",
    "eObs[index,0] = lamostgaia[\"era\"][index]/180.*np.pi\n",
    "eObs[index,1] = lamostgaia[\"edec\"][index]/180.*np.pi\n",
    "Obs[index,4]  = lamostgaia[\"mra\"][index]\n",
    "Obs[index,5]  = lamostgaia[\"mdec\"][index]\n",
    "eObs[index,4] = lamostgaia[\"emra\"][index]\n",
    "eObs[index,5] = lamostgaia[\"emdec\"][index]\n",
    "print(\"Replaced \"+str(np.sum(index))+\" stars with missing Gaia data with original data...\")\n",
    "\n",
    "# Replace stars with NaN proper motions with original UCAC5 proper motions\n",
    "index = (np.isnan(lamostgaia[\"gaiadr2_pmra\"])) | \\\n",
    "        (np.isnan(lamostgaia[\"gaiadr2_pmdec\"])) | \\\n",
    "        (np.isnan(lamostgaia[\"gaiadr2_pmra_error\"])) | \\\n",
    "        (np.isnan(lamostgaia[\"gaiadr2_pmdec_error\"]))\n",
    "Obs[index,4]  = lamostgaia[\"mra\"][index]\n",
    "Obs[index,5]  = lamostgaia[\"mdec\"][index]\n",
    "eObs[index,4] = lamostgaia[\"emra\"][index]\n",
    "eObs[index,5] = lamostgaia[\"emdec\"][index]\n",
    "print(\"Replaced \"+str(np.sum(index))+\" stars having NaN proper motions with original UCAC5 proper motions...\")\n",
    "\n",
    "# Remove stars that are likely to be massive merged stars\n",
    "idx_merged_massive = (afe>0.12) & (Obs[:,8]<5.)\n",
    "print(\"Removing \"+str(np.sum(idx_merged_massive))+\" stars that are likely to be merged stars.\")\n",
    "Obs  = Obs[~idx_merged_massive,:]\n",
    "eObs = eObs[~idx_merged_massive,:]\n",
    "feh  = feh[~idx_merged_massive]\n",
    "afe  = afe[~idx_merged_massive]\n",
    "\n",
    "# Select low-alpha population\n",
    "slope         = -0.07\n",
    "yintercept    = 0.12\n",
    "afemax        = yintercept + slope*feh\n",
    "idx_lowalpha  = afemax > afe\n",
    "print(\"Removing a further \"+str(len(feh) - np.sum(idx_lowalpha))+\" stars that belong to the high-alpha disc.\")\n",
    "Obs  = Obs[idx_lowalpha,:]\n",
    "eObs = eObs[idx_lowalpha,:]\n",
    "feh  = feh[idx_lowalpha]\n",
    "afe  = afe[idx_lowalpha]\n",
    "\n",
    "# Select in plane if desired\n",
    "if (MODELTYPE==\"zsel\"):\n",
    "    solpos = np.array([8.2,0.014,-8.6,13.9+232.8,7.1]) # McMillan 2017\n",
    "    wg = ct.EquatorialToGalactic(Obs)\n",
    "    wp = ct.GalacticToPolar(wg,solpos)\n",
    "    z  = wp[:,2]\n",
    "    idx_beyondz = ((np.abs(z)<ZMIN) | (np.abs(z)>ZMAX))\n",
    "    print(\"Removing a further \"+str(np.sum(idx_beyondz))+\" stars that are beyond the selection in z.\")\n",
    "    Obs  = Obs[~idx_beyondz,:]\n",
    "    eObs = eObs[~idx_beyondz,:]\n",
    "    feh  = feh[~idx_beyondz]\n",
    "    afe  = afe[~idx_beyondz]\n",
    "\n",
    "nstars   = len(Obs)\n",
    "print(nstars)\n",
    "\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate MC, SF, and Jacobian determinant samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...defining observational volume...\n",
      " \n",
      "Minima of observational volume:\n",
      "[ 0.00000000e+00 -1.57079633e+00  1.00000000e-02 -1.00000000e+03\n",
      " -2.10970464e+02 -2.10970464e+02 -1.00000000e+00 -4.00000000e-01\n",
      "  5.00000000e-01]\n",
      " \n",
      "Maxima of observational volume:\n",
      "[6.28318531e+00 1.57079633e+00 1.90000000e+01 1.00000000e+03\n",
      " 2.10970464e+02 2.10970464e+02 7.00000000e-01 4.00000000e-01\n",
      " 1.31000000e+01]\n",
      " \n",
      "     Monte Carlo samples being evaluated...\n",
      "     Calculating selection function...\n",
      "     Calculating Jacobian determinant...\n",
      "...done.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Solar position\n",
    "solpos = np.array([8.2,0.014,-8.6,13.9+232.8,7.1]) # McMillan 2017\n",
    "\n",
    "# Selection function object\n",
    "mwsf = MilkyWaySF.LamostRedClumpsLowAlphaDiscSF(SFFILE)\n",
    "\n",
    "# Instantiate data model class\n",
    "datamodel = DM.DataModel(Obs,eObs,mwsf,solpos,modelType=MODELTYPE,zmin=ZMIN,zmax=ZMAX)\n",
    "\n",
    "# Calculate Monte Carlo samples for each star for error convolution integral\n",
    "datamodel.CreateMcObs(NMC,MCFILE)\n",
    "\n",
    "# Calculate selection function for Monte Carlo samples of stars\n",
    "print(\"     Calculating selection function...\")\n",
    "datamodel.CalcSF()\n",
    "\n",
    "# Calculate Jacobian determinant for Monte Carlo samples of stars\n",
    "print(\"     Calculating Jacobian determinant...\")\n",
    "datamodel.CalcJacDet()\n",
    "\n",
    "print(\"...done.\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save instance of data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATAMODELFILE, \"wb\") as dillfile:\n",
    "    dill.dump(datamodel, dillfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
